{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (0.2.48)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (5.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (2024.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (3.17.7)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Requirement already satisfied: bs4 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: nbformat in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.21.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (307)\n",
      "Requirement already satisfied: plotly in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (5.24.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from plotly) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: html5lib in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\jochoniah.nzomo\\appdata\\local\\anaconda3\\envs\\datasciences\\lib\\site-packages (from html5lib) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install bs4\n",
    "!pip install nbformat\n",
    "%pip install plotly\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4 html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"), vertical_spacing = .3)\n",
    "    stock_data_specific = stock_data[stock_data.Date <= '2021--06-14']\n",
    "    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True), y=stock_data_specific.Close.astype(\"float\"), name=\"Share Price\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True), y=revenue_data_specific.Revenue.astype(\"float\"), name=\"Revenue\"), row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    fig.update_layout(showlegend=False,\n",
    "    height=900,\n",
    "    title=stock,\n",
    "    xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Use yfinance to Extract Stock Data¶\n",
    "Using the Ticker function enter the ticker symbol of the stock we want to extract data on to create a ticker object. The stock is Tesla and its ticker symbol is TSLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2023-11-08 00:00:00-05:00  223.149994  224.149994  217.639999  222.110001   \n",
      "2023-11-09 00:00:00-05:00  219.750000  220.800003  206.679993  209.979996   \n",
      "2023-11-10 00:00:00-05:00  210.029999  215.380005  205.690002  214.649994   \n",
      "2023-11-13 00:00:00-05:00  215.600006  225.399994  211.610001  223.710007   \n",
      "2023-11-14 00:00:00-05:00  235.029999  238.139999  230.720001  237.410004   \n",
      "...                               ...         ...         ...         ...   \n",
      "2024-11-01 00:00:00-04:00  252.039993  254.000000  246.630005  248.979996   \n",
      "2024-11-04 00:00:00-05:00  244.559998  248.899994  238.880005  242.839996   \n",
      "2024-11-05 00:00:00-05:00  247.339996  255.279999  246.210007  251.440002   \n",
      "2024-11-06 00:00:00-05:00  284.670013  289.589996  275.619995  288.529999   \n",
      "2024-11-07 00:00:00-05:00  288.890015  299.750000  285.519989  296.910004   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2023-11-08 00:00:00-05:00  106584800        0.0           0.0  \n",
      "2023-11-09 00:00:00-05:00  142110500        0.0           0.0  \n",
      "2023-11-10 00:00:00-05:00  130994000        0.0           0.0  \n",
      "2023-11-13 00:00:00-05:00  140447600        0.0           0.0  \n",
      "2023-11-14 00:00:00-05:00  149771600        0.0           0.0  \n",
      "...                              ...        ...           ...  \n",
      "2024-11-01 00:00:00-04:00   57544800        0.0           0.0  \n",
      "2024-11-04 00:00:00-05:00   68802400        0.0           0.0  \n",
      "2024-11-05 00:00:00-05:00   69282500        0.0           0.0  \n",
      "2024-11-06 00:00:00-05:00  165228700        0.0           0.0  \n",
      "2024-11-07 00:00:00-05:00  116871100        0.0           0.0  \n",
      "\n",
      "[252 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Use yfinance to Extract Stock Data¶\n",
    "# Using the Ticker function enter the ticker symbol of the stock we want to extract data on to create a ticker object. The stock is Tesla and its ticker symbol is TSLA.\n",
    "tsla_ticker = yf.Ticker(\"TSLA\")\n",
    "# get Tesla's historical stock data\n",
    "tesla_data = tsla_ticker.history(period=\"1y\")\n",
    "print(tesla_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667  281494500   \n",
      "2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667  257806500   \n",
      "2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000  123282000   \n",
      "2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   77097000   \n",
      "2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000  103003500   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-06-29 00:00:00-04:00        0.0           0.0  \n",
      "2010-06-30 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-01 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-02 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-06 00:00:00-04:00        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Extract historical stock data for the maximum period and save it in a DataFrame\n",
    "tesla_data = tsla_ticker.history(period=\"max\")\n",
    "\n",
    "# Display the first few rows of the data to confirm\n",
    "print(tesla_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date      Open      High       Low     Close  \\\n",
      "0 2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667   \n",
      "1 2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667   \n",
      "2 2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000   \n",
      "3 2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   \n",
      "4 2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000   \n",
      "\n",
      "      Volume  Dividends  Stock Splits  \n",
      "0  281494500        0.0           0.0  \n",
      "1  257806500        0.0           0.0  \n",
      "2  123282000        0.0           0.0  \n",
      "3   77097000        0.0           0.0  \n",
      "4  103003500        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract historical stock data for the maximum period and save it in a DataFrame\n",
    "tesla_data = tsla_ticker.history(period=\"max\")\n",
    "\n",
    "# Step 3: Reset the index of the DataFrame\n",
    "tesla_data.reset_index(inplace=True)\n",
    "\n",
    "# Step 4: Display the first five rows of the DataFrame\n",
    "print(tesla_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Use Webscraping to Extract Tesla Revenue Data¶\n",
    "Use the requests library to download the webpage https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm Save the text of the response as a variable named html_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\"> <!--<![endif]-->\n",
      "    <head>\n",
      "        <meta charset=\"utf-8\">\n",
      "        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
      "\t\t<link rel=\"canonical\" href=\"https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\" />\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage to be downloaded\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm\"\n",
    "\n",
    "# Send a GET request to the URL and store the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the text of the response as a variable named html_data\n",
    "html_data = response.text\n",
    "\n",
    "# Display a part of html_data to confirm\n",
    "print(html_data[:500])  # Displaying the first 500 characters for a quick check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <link href=\"https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\" rel=\"canonical\"/>\n",
      "  <title>\n",
      "   Te\n"
     ]
    }
   ],
   "source": [
    "# Parse the HTML data using BeautifulSoup\n",
    "soup = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Display the parsed HTML to confirm\n",
    "print(soup.prettify()[:500])  # Displaying the first 500 characters for a quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date Revenue\n",
      "0   2022-09-30   21454\n",
      "1   2022-06-30   16934\n",
      "2   2022-03-31   18756\n",
      "3   2021-12-31   17719\n",
      "4   2021-09-30   13757\n",
      "5   2021-06-30   11958\n",
      "6   2021-03-31   10389\n",
      "7   2020-12-31   10744\n",
      "8   2020-09-30    8771\n",
      "9   2020-06-30    6036\n",
      "10  2020-03-31    5985\n",
      "11  2019-12-31    7384\n",
      "12  2019-09-30    6303\n",
      "13  2019-06-30    6350\n",
      "14  2019-03-31    4541\n",
      "15  2018-12-31    7226\n",
      "16  2018-09-30    6824\n",
      "17  2018-06-30    4002\n",
      "18  2018-03-31    3409\n",
      "19  2017-12-31    3288\n",
      "20  2017-09-30    2985\n",
      "21  2017-06-30    2790\n",
      "22  2017-03-31    2696\n",
      "23  2016-12-31    2285\n",
      "24  2016-09-30    2298\n",
      "25  2016-06-30    1270\n",
      "26  2016-03-31    1147\n",
      "27  2015-12-31    1214\n",
      "28  2015-09-30     937\n",
      "29  2015-06-30     955\n",
      "30  2015-03-31     940\n",
      "31  2014-12-31     957\n",
      "32  2014-09-30     852\n",
      "33  2014-06-30     769\n",
      "34  2014-03-31     621\n",
      "35  2013-12-31     615\n",
      "36  2013-09-30     431\n",
      "37  2013-06-30     405\n",
      "38  2013-03-31     562\n",
      "39  2012-12-31     306\n",
      "40  2012-09-30      50\n",
      "41  2012-06-30      27\n",
      "42  2012-03-31      30\n",
      "43  2011-12-31      39\n",
      "44  2011-09-30      58\n",
      "45  2011-06-30      58\n",
      "46  2011-03-31      49\n",
      "47  2010-12-31      36\n",
      "48  2010-09-30      31\n",
      "49  2010-06-30      28\n",
      "50  2010-03-31      21\n",
      "51  2009-12-31        \n",
      "52  2009-09-30      46\n",
      "53  2009-06-30      27\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Fetch the HTML data\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm\"\n",
    "response = requests.get(url)\n",
    "html_data = response.text\n",
    "\n",
    "# Step 1: Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Step 2: Create an empty DataFrame for Tesla revenue data\n",
    "tesla_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\n",
    "\n",
    "# Step 3: Locate the relevant table by its content\n",
    "tables = soup.find_all('table')\n",
    "revenue_table = None\n",
    "for table in tables:\n",
    "    if \"Tesla Quarterly Revenue\" in table.text:\n",
    "        revenue_table = table\n",
    "        break\n",
    "\n",
    "# Step 4: Check if the Tesla Quarterly Revenue table was found\n",
    "if revenue_table:\n",
    "    # Step 5: Iterate through each row in the table's body\n",
    "    rows = revenue_table.find('tbody').find_all('tr')\n",
    "    for row in rows:\n",
    "        # Step 6: Extract date and revenue data from each row\n",
    "        cols = row.find_all('td')\n",
    "        date = cols[0].text.strip()\n",
    "        revenue = cols[1].text.strip().replace('$', '').replace(',', '')  # Clean up the revenue data\n",
    "        \n",
    "        # Step 7: Append the data as a new row to the DataFrame using pd.concat()\n",
    "        new_row = pd.DataFrame({\"Date\": [date], \"Revenue\": [revenue]})\n",
    "        tesla_revenue = pd.concat([tesla_revenue, new_row], ignore_index=True)\n",
    "\n",
    "# Step 8: Display the DataFrame\n",
    "print(tesla_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_revenue[\"Revenue\"] = tesla_revenue[\"Revenue\"].str.replace(',', '').str.replace('$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_revenue.dropna(inplace=True)\n",
    "\n",
    "tesla_revenue = tesla_revenue[tesla_revenue['Revenue'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2009-09-30</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2009-06-30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Revenue\n",
       "48  2010-09-30      31\n",
       "49  2010-06-30      28\n",
       "50  2010-03-31      21\n",
       "52  2009-09-30      46\n",
       "53  2009-06-30      27"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# Display the last 5 row of the tesla_revenue dataframe using the tail function. Take a screenshot of the results.\n",
    "tesla_revenue.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2023-11-08 00:00:00-05:00  13.510000  13.760000  13.280000  13.280000   \n",
      "2023-11-09 00:00:00-05:00  13.250000  13.320000  12.700000  12.700000   \n",
      "2023-11-10 00:00:00-05:00  12.810000  12.970000  12.350000  12.540000   \n",
      "2023-11-13 00:00:00-05:00  12.500000  12.530000  11.830000  12.140000   \n",
      "2023-11-14 00:00:00-05:00  12.750000  13.390000  12.690000  12.900000   \n",
      "...                              ...        ...        ...        ...   \n",
      "2024-11-04 00:00:00-05:00  22.200001  22.650000  21.879999  22.330000   \n",
      "2024-11-05 00:00:00-05:00  22.320000  23.200001  22.270000  22.990000   \n",
      "2024-11-06 00:00:00-05:00  23.309999  23.820000  22.900000  23.100000   \n",
      "2024-11-07 00:00:00-05:00  23.070000  23.660000  22.809999  23.450001   \n",
      "2024-11-08 00:00:00-05:00  23.070000  23.450001  23.330000  23.424500   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2023-11-08 00:00:00-05:00  1705600        0.0           0.0  \n",
      "2023-11-09 00:00:00-05:00  2750100        0.0           0.0  \n",
      "2023-11-10 00:00:00-05:00  3872400        0.0           0.0  \n",
      "2023-11-13 00:00:00-05:00  4318500        0.0           0.0  \n",
      "2023-11-14 00:00:00-05:00  5187500        0.0           0.0  \n",
      "...                            ...        ...           ...  \n",
      "2024-11-04 00:00:00-05:00  4300200        0.0           0.0  \n",
      "2024-11-05 00:00:00-05:00  5858400        0.0           0.0  \n",
      "2024-11-06 00:00:00-05:00  6648000        0.0           0.0  \n",
      "2024-11-07 00:00:00-05:00  5454100        0.0           0.0  \n",
      "2024-11-08 00:00:00-05:00   206203        0.0           0.0  \n",
      "\n",
      "[253 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a ticker object for GameStop\n",
    "gme_ticker = yf.Ticker(\"GME\")\n",
    "\n",
    "# Get GameStop's historical stock data\n",
    "gamestop_data = gme_ticker.history(period=\"1y\")\n",
    "print(gamestop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-02-13 00:00:00-05:00</th>\n",
       "      <td>1.620129</td>\n",
       "      <td>1.693350</td>\n",
       "      <td>1.603296</td>\n",
       "      <td>1.691667</td>\n",
       "      <td>76216000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-02-14 00:00:00-05:00</th>\n",
       "      <td>1.712707</td>\n",
       "      <td>1.716074</td>\n",
       "      <td>1.670626</td>\n",
       "      <td>1.683250</td>\n",
       "      <td>11021600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-02-15 00:00:00-05:00</th>\n",
       "      <td>1.683251</td>\n",
       "      <td>1.687459</td>\n",
       "      <td>1.658002</td>\n",
       "      <td>1.674834</td>\n",
       "      <td>8389600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-02-19 00:00:00-05:00</th>\n",
       "      <td>1.666418</td>\n",
       "      <td>1.666418</td>\n",
       "      <td>1.578047</td>\n",
       "      <td>1.607504</td>\n",
       "      <td>7410400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-02-20 00:00:00-05:00</th>\n",
       "      <td>1.615921</td>\n",
       "      <td>1.662210</td>\n",
       "      <td>1.603296</td>\n",
       "      <td>1.662210</td>\n",
       "      <td>6892800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open      High       Low     Close    Volume  \\\n",
       "Date                                                                          \n",
       "2002-02-13 00:00:00-05:00  1.620129  1.693350  1.603296  1.691667  76216000   \n",
       "2002-02-14 00:00:00-05:00  1.712707  1.716074  1.670626  1.683250  11021600   \n",
       "2002-02-15 00:00:00-05:00  1.683251  1.687459  1.658002  1.674834   8389600   \n",
       "2002-02-19 00:00:00-05:00  1.666418  1.666418  1.578047  1.607504   7410400   \n",
       "2002-02-20 00:00:00-05:00  1.615921  1.662210  1.603296  1.662210   6892800   \n",
       "\n",
       "                           Dividends  Stock Splits  \n",
       "Date                                                \n",
       "2002-02-13 00:00:00-05:00        0.0           0.0  \n",
       "2002-02-14 00:00:00-05:00        0.0           0.0  \n",
       "2002-02-15 00:00:00-05:00        0.0           0.0  \n",
       "2002-02-19 00:00:00-05:00        0.0           0.0  \n",
       "2002-02-20 00:00:00-05:00        0.0           0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract historical stock data for the maximum period and save it in a DataFrame\n",
    "gme_data = gme_ticker.history(period=\"max\")\n",
    "\n",
    "# Display the first few rows of the data to confirm\n",
    "gme_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date      Open      High       Low     Close    Volume  \\\n",
      "0 2002-02-13 00:00:00-05:00  1.620129  1.693350  1.603296  1.691667  76216000   \n",
      "1 2002-02-14 00:00:00-05:00  1.712707  1.716074  1.670626  1.683250  11021600   \n",
      "2 2002-02-15 00:00:00-05:00  1.683251  1.687459  1.658002  1.674834   8389600   \n",
      "3 2002-02-19 00:00:00-05:00  1.666418  1.666418  1.578047  1.607504   7410400   \n",
      "4 2002-02-20 00:00:00-05:00  1.615921  1.662210  1.603296  1.662210   6892800   \n",
      "\n",
      "   Dividends  Stock Splits  \n",
      "0        0.0           0.0  \n",
      "1        0.0           0.0  \n",
      "2        0.0           0.0  \n",
      "3        0.0           0.0  \n",
      "4        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Reset the index of the gme_data DataFrame\n",
    "gme_data.reset_index(inplace=True)\n",
    "\n",
    "# Display the first five rows of the gme_data DataFrame\n",
    "print(gme_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question 4: Use Webscraping to Extract GME Revenue Data¶\n",
    "Use the requests library to download the webpage https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/stock.html. Save the text of the response as a variable named html_data_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<!-- saved from url=(0105)https://web.archive.org/web/20200814131437/https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue -->\\n<html class=\" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface g'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL of the webpage to be downloaded\n",
    "url_2 = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/stock.html\"\n",
    "\n",
    "# Send a GET request to the URL and store the response\n",
    "response_2 = requests.get(url_2)\n",
    "\n",
    "# Save the text of the response as a variable named html_data_2\n",
    "html_data_2 = response_2.text\n",
    "\n",
    "# Display a part of html_data_2 to confirm\n",
    "html_data_2[:500]  # Displaying the first 500 characters for a quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <link href=\"https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\" rel=\"canonical\"/>\n",
      "  <title>\n",
      "   Te\n"
     ]
    }
   ],
   "source": [
    "# Assuming html_data contains the HTML content from the previous step\n",
    "soup = BeautifulSoup(html_data, 'html.parser')  # or 'html5lib' as the parser\n",
    "\n",
    "# Display a portion of the parsed HTML to confirm successful parsing\n",
    "print(soup.prettify()[:500])  # Displaying the first 500 characters for a quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2523320663.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 36\u001b[1;36m\u001b[0m\n\u001b[1;33m    Explanation:\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Download the HTML data (use the appropriate URL for the GameStop data)\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm\"\n",
    "response = requests.get(url)\n",
    "html_data = response.text\n",
    "\n",
    "# Step 1: Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Step 2: Create an empty DataFrame for GameStop revenue data\n",
    "gme_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\n",
    "\n",
    "# Step 3: Locate the GameStop Revenue table by checking for its text content\n",
    "tables = soup.find_all('table')\n",
    "revenue_table = None\n",
    "for table in tables:\n",
    "    if \"GameStop Quarterly Revenue\" in table.text:\n",
    "        revenue_table = table\n",
    "        break\n",
    "\n",
    "# Step 4: Check if the GameStop Quarterly Revenue table was found\n",
    "if revenue_table:\n",
    "    # Step 5: Iterate through each row in the table's body\n",
    "    rows = revenue_table.find('tbody').find_all('tr')\n",
    "    for row in rows:\n",
    "        # Step 6: Extract date and revenue data from each row\n",
    "        cols = row.find_all('td')\n",
    "        date = cols[0].text.strip()\n",
    "        revenue = cols[1].text.strip().replace('$', '').replace(',', '')  # Remove dollar sign and comma\n",
    "        \n",
    "        # Step 7: Append the data as a new row to the DataFrame using pd.concat()\n",
    "        new_row = pd.DataFrame({\"Date\": [date], \"Revenue\": [revenue]})\n",
    "        gme_revenue = pd.concat([gme_revenue, new_row], ignore_index=True)\n",
    "\n",
    "# Step 8: Display the DataFrame\n",
    "print(gme_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datasciences",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
